(window.webpackJsonp=window.webpackJsonp||[]).push([[0],[,,,,,,,,,,,,,function(e,t,n){},,,function(e,t,n){e.exports=n.p+"static/media/full-view.76784da0.svg"},,,,function(e,t,n){e.exports=n(112)},,,,,function(e,t,n){},,function(e,t,n){},,function(e,t,n){},,,,,function(e,t,n){e.exports='<h3 id="roma-interactive-fabrication-with-a-robotic-3d-printer">RoMA: Interactive Fabrication with a Robotic 3D Printer</h3>\n<h6 id="january-2017-september-2017">January 2017 - September 2017</h6>\n<span style="display:block;text-align:center">\n<img src="'+n(35)+'" alt="That\'s me in that pic" width="75%" style="margin: 0 auto"/>\n*That\'s me in the pic!*\n</span>\n\n<h5 id="authors-huaishu-peng-jimmy-briggs-cheng-yao-wang-kevin-guo-joseph-kider-stefanie-mueller-patrick-baudisch-fran-ois-guimbreti-re">Authors: Huaishu Peng, Jimmy Briggs, Cheng-Yao Wang, <strong>Kevin Guo</strong>, Joseph Kider, Stefanie Mueller, Patrick Baudisch, Fran\xe7ois Guimbreti\xe8re</h5>\n<h5 id="2018-conference-on-human-factors-in-computing-systems-chi-2018-">2018 Conference on Human Factors in Computing Systems <strong>(CHI 2018)</strong></h5>\n<p><a href="https://drive.google.com/file/d/1dfZdkDhoW0ewAtWpj-f13B29UcXLNtwD/view?usp=sharing">Read the Paper here</a></p>\n<span style="display:block;text-align:center">\n<iframe width="720" height="405" src="https://www.youtube.com/embed/K_wWuYD1Fkg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>\n</span>\n\n<h3 id="abstract">Abstract</h3>\n<p>We present the Robotic Modeling Assistant (RoMA), an interactive fabrication system providing a fast, precise, hands-on and in-situ modeling experience. As a designer creates a new model using RoMA AR CAD editor, features are constructed concurrently by a 3D printing robotic arm sharing the same design volume. The partially printed physical model then serves as a tangible reference for the designer as she adds new elements to her design. RoMA\'s proxemics-inspired handshake mechanism between the designer and the 3D printing robotic arm allows the designer to quickly interrupt printing to access a printed area or to indicate that the robot can take full control of the model to finish printing. RoMA lets users integrate real-world constraints into a design rapidly, allowing them to create well-proportioned tangible artifacts or to extend existing objects. We conclude by presenting the strengths and limitations of our current design.</p>\n<h3 id="ui-ux">UI/UX</h3>\n<p>My main role within the project was designing and implementing the interface for the augmented reality CAD editor. The main UI element in the program was the marking menu, which allowed users to select a drawing operation from the controller. Clicking the joystick would open the menu and the user would be able to select a menu item simply by moving the joystick to the sector of the menu and clicking or holding the joystick in that position.</p>\n<p>The process of making an object in almost every CAD program starts off very similar to the screenshot below...</p>\n<span style="display:block;text-align:center">\n<img src="'+n(36)+'" alt="Solidworks" width="75%" style="margin: 0 auto"/>\n*What a 2D sketch looks like on Solidworks, an existing CAD application*\n</span>\n\n<p>...as a flat 2D drawing. While this is great for precise shapes on blank backgrounds with experienced users on a flat screen, it wouldn\'t make much sense in an AR environment with users who weren\'t entirely familiar with modeling software. </p>\n<p>I proposed a hybrid system, in which the user would point and &quot;project&quot; a 2D element such as a curve or a line or a point onto a selected plane. Below is the 4 page storyboard I made of a user creating an airplane using the hybrid system in RoMA.</p>\n<span style="display:block;text-align:center">\n<img src="'+n(37)+'" alt="workflow" width="85%" style="margin: 0 auto"/>\n*My initial idea for a workflow, which borrowed heavily from the 2D sketching framework I knew from being a Solidworks user*\n</span>\n\n<p>While it could work, after some discussion with the rest of the team, I realized that such a system wouldn\'t take full advantage of working in AR. We came to a compromise, drawing elements free floating in 3D space with the exception of certain actions that required elements to be defined by a plane or a surface (such as rotation or lofting).</p>\n<p>I proposed 3 menu interaction schemes and made interactive Javascript prototypes to demonstrate them in Framer (all three prototypes are below).</p>\n<div class="row">\n    <div class="four columns" style="display:block;text-align:center">\n        <h4>Stack Menu</h4>\n        <img src="'+n(38)+'" alt="AR Interactions" width="50%" style="margin: 0 auto"><img/>\n    </div>\n    <div class="four columns" style="display:block;text-align:center">\n        <h4>Tree Menu</h4>\n        <img src="'+n(39)+'" alt="AR Interactions" width="50%" style="margin: 0 auto"><img/>\n    </div>\n    <div class="four columns" style="display:block;text-align:center">\n        <h4>Ring Menu</h4>\n        <img src="'+n(40)+'" alt="AR Interactions" width="50%" style="margin: 0 auto"><img/>\n    </div>\n</div>\n<div class="row">\n    <div class="four columns" style="display:block;text-align:center; height:350px; overflow:hidden; margin-bottom: 2em">\n        <iframe class="framer" src="https://framer.cloud/ilfyY/" width="600" height="900" style="display:block;transform:scale(0.5);transform-origin: top left; border:none"></iframe>\n    </div>\n    <div class="four columns" style="display:block;text-align:center; height:350px; overflow:hidden; margin-bottom: 2em">\n        <iframe class="framer" src="https://framer.cloud/agbTc/" width="600" height="900" style="display:block;transform:scale(0.5);transform-origin: top left; border:none;"></iframe>\n    </div>\n    <div class="four columns" style="display:block;text-align:center; height:350px; overflow:hidden; margin-bottom: 2em">\n        <iframe class="framer" src="https://framer.cloud/HcxQi/" width="600" height="900" style="display:block;transform:scale(0.5);transform-origin: top left;border:none"></iframe>\n    </div>\n</div>\n\n<p>The stack menu was chosen as the menu because it was the easiest to implement, didn\'t clutter up too much of the user\'s field of view, and conformed more directly to the user\'s actions. However, I realized pretty early on that the stack menu\'s design made it hard to remember what action was chosen and what you had to do to complete the task. To aid with that, I used the blank space in the middle of the menu as a reminder of why an item or action needed to be selected (shown below).</p>\n<span style="display:block;text-align:center">\n<img src="'+n(41)+'" alt="Label" width="50%" style="margin: 0 auto"/>\n*The Logical Structure of the Marking Menu*\n</span>\n\n<p>I had to make one for every action and as you can see below...</p>\n<span style="display:block;text-align:center">\n<img src="'+n(42)+'" alt="Label" width="50%" style="margin: 0 auto"/>\n*These were about as annoying to make as it seems it would*\n</span>\n\n<p>...there were a lot of them. Along with the menus, I created a whole new set of icons for RoMA.</p>\n<span style="display:block;text-align:center">\n<img src="'+n(43)+'" alt="Label" width="75%" style="margin: 0 auto"/>\n*An entirely new set of icons for RoMA*\n</span>\n\n<p>After wrangling with a custom C# engine specifically for RoMA <a href="http://jimmybriggs.net/">(courtesy from the talented Jimmy Briggs)</a>, my marking menu eventually was integrated with the system and was demoed for interested researchers and designers alike.</p>\n<span style="display:block;text-align:center">\n<img src="'+n(44)+'" alt="AR Interactions" width="85%" style="margin: 0 auto"/>\n*Marking menu in action in the AR CAD editor*\n</span>\n\n<span style="display:block;text-align:center">\n<img src="'+n(45)+'" alt="The Team" width="85%" style="margin: 0 auto"/>\n*(From left to right) Huaishu Peng, Eric (Cheng-Yao) Wang, Me (Kevin Guo), & Jimmy Briggs. The best team I could ask for.*\n</span>\n'},function(e,t,n){e.exports=n.p+"static/media/designscene.d735447f.JPG"},function(e,t,n){e.exports=n.p+"static/media/screenshot.7b0274c2.png"},function(e,t,n){e.exports=n.p+"static/media/workflow.92ac1883.png"},function(e,t,n){e.exports=n.p+"static/media/stack.0c7c5e76.svg"},function(e,t,n){e.exports=n.p+"static/media/tree.1b3953e1.svg"},function(e,t,n){e.exports=n.p+"static/media/ring.23743f56.svg"},function(e,t,n){e.exports=n.p+"static/media/roma_labels.258a638c.png"},function(e,t,n){e.exports=n.p+"static/media/entire_set.207bfff3.png"},function(e,t,n){e.exports=n.p+"static/media/icons.3993ecea.svg"},function(e,t,n){e.exports=n.p+"static/media/ar_interaction.9b8cb16c.jpg"},function(e,t,n){e.exports=n.p+"static/media/team.034a7500.jpg"},function(e,t,n){e.exports='<h3 id="crochetmatic-volumetric-3d-knitting">CrochetMatic: Volumetric 3D Knitting</h3>\n<h6 id="may-2017-may-2018">May 2017 - May 2018</h6>\n<h5 id="people-kevin-guo-olav-imsdahl-fran-ois-guimbreti-re-scott-hudson">People: <strong>Kevin Guo</strong>, Olav Imsdahl, Fran\xe7ois Guimbreti\xe8re, Scott Hudson</h5>\n<div class="row">\n    <div class="six columns" style="display:block;text-align:center">\n        <img src="'+n(47)+'" alt="Crochetmatic" width="100%" style="margin: 0 auto"/>\n    </div>\n    <div class="six columns" style="display:block;text-align:center">\n        <img src="'+n(16)+'" alt="That\'s me in that pic" width="100%" style="margin: 0 auto"/>\n    </div>\n</div>\n\n<p>I worked on CrochetMatic during my time at <a href="https://www.cs.cornell.edu/~francois/">Prof. Fran\xe7ois Guimbreti\xe8re</a>\'s Design Lab. CrochetMatic was easily one of the most time-consuming and difficult projects. While I didn\'t reach the ultimate goal, I believe that I learned an immense amount from my struggles with this project.</p>\n<h3 id="the-start">The Start</h3>\n<p>The initial idea was to build a machine that could build knitted objects the same way 3D printers build their prints: additive and layer-by-layer. But while plastic has relatively predictable properties and can be put through an extruder, a length of yarn\'s properties can change from bundle to bundle. Also, it can get caught on small mechanisms which makes it hard to build around. Furthermore, the idea of knitting entire 3D volumes (both the exterior and interior), whether by hand or machine had never really been tried before. The closest antecedent to the project was <a href="https://www.disneyresearch.com/publication/machine-knitting-compiler/">a 3D knitting compiler</a> from Carnegie Mellon University but even that knitting compiler only created knitted tubes that had to be filled afterwards.</p>\n<p>At the suggestion of <a href="http://www.cs.cornell.edu/~srm/">Prof. Steve Marschner</a>, the preeminent computer graphics professor at Cornell (he won an Oscar for his CG research), the individual knits were throught of as a series of voxels, or volumes in a 3D grid. This was coming off of his previous work simulating knit clothes <a href="http://www.cs.cornell.edu/projects/YarnCloth/">(more details here.)</a></p>\n<h3 id="simulations">Simulations</h3>\n<p>After spending the first two weeks of summer learning how to knit, I learned that the knits followed a regular pattern and that the best way to make a &quot;layer&quot; of knits was to spiral outwards in with a series of concentric layers. Each individual layer would be independent of the ones inside and outside of it except for &quot;linking&quot; knits that connected that layer to the one outside of it. I ended up building computer models in Fusion360 of each type of knit that would conform to the voxels.</p>\n<div class="row">\n    <div class="six columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(48)+'" alt="Basic" width="75%" style="margin: 0 auto"/>\n        *Initial observation sketch of a unit voxel*\n        </span>\n        <span style="display:block;text-align:center">\n        <img src="'+n(49)+'" alt="Basic" width="75%" style="margin: 0 auto"/>\n        *Final modeled basic knit voxel*\n        </span>\n    </div>\n    <div class="six columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(50)+'" alt="Basic" width="75%" style="margin: 0 auto"/>\n        *Initial observation sketch of a junction voxel*\n        </span>\n        <span style="display:block;text-align:center">\n        <img src="'+n(51)+'" alt="Junction" width="75%" style="margin: 0 auto"/>\n        *Final modeled junction knit voxels*\n        </span>\n    </div>\n</div>\n\n<p>Each knit followed a path of points, which I was able to export and joint together to form a single &quot;strand&quot; of points. This strand was inputted into a modified version of a <a href="https://www.cs.cornell.edu/projects/rodsound/">C++ rod simulator</a> developed by one of Prof. Marschner\'s PhDs <a href="https://www.cs.cornell.edu/~ers/">Eston</a>. Each simulation, even though only one second long, required hours of computation, a couple took over 24 hours. But in the end, we got the results, which seemed to match the real life knits I made.</p>\n<div class="row">\n    <div class="four columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(52)+'" alt="single" width="100%" style="margin: 0 auto"/>\n        *Simulating a single layer*\n        </span>\n    </div>\n    <div class="four columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(53)+'" alt="multiple" width="100%" style="margin: 0 auto"/>\n        *Simulating  multiple layers*\n        </span>\n    </div>\n    <div class="four columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(54)+'" alt="Label" width="100%" style="margin: 0 auto"/>\n        *Knitted "Cube" I made*\n        </span>\n    </div>\n</div>\n\n<h3 id="building-the-machine">Building the Machine</h3>\n<p>With an idea of what the final knits would look like, it was onto building the machine itself, which was made up of two separate parts:</p>\n<ol>\n<li>An XY Bed powered by an Arduino Mega and RAMPS board</li>\n<li>An array of needles powered by a Teensy 3.5 board</li>\n</ol>\n<span style="display:block;text-align:center">\n<img src="'+n(55)+'" alt="Label" width="75%" style="margin: 0 auto"/>\n</span>\n\n<h3 id="xy-bed">XY Bed</h3>\n<p>The XY bed was built and assembled by <a href="https://hcii.cmu.edu/people/scott-hudson">Prof. Scott Hudson</a> from Carnegie Mellon University. Based off a regular 3D printer bed, it\'s made up of a 80-20 frame driven by an Arduino Mega with a RAMPS board mounted on it. The Arduino Mega controlled most of the movements on the machine with a RAMPS 1.4 board. The RAMPS board was typically meant for building DIY 3D printers, but because of CrochetMatic didn\'t have a heating element, I had to put two resistors and a potentiometer (a dial) attached to where the heat sensors were supposed to be. This was to trick the board into thinking that there is a heating element on the machine (there isn\u2019t) so that it will use the extruder properly (how the latch servos and the yarn extruder are operated).</p>\n<h3 id="needle-array">Needle Array</h3>\n<p>3D knitting (or Volumetric knitting) was untried while I was working on the project, and the most daunting part was figuring out how to build the needles. The idea was to build an entire &quot;bed&quot; of needles, but what they would look like and how they would work was completely unknown. We couldn\'t copy them from existing knitting machine needles, which are meant solely for flat 2D planes, but we could use some of the basics of the designs to base how the needles would work. The most helpful was <a href="https://www.disneyresearch.com/publication/machine-knitting-compiler/">A Compiler for 3D Machine Knitting</a> made in Carnegie Mellon University, which described a way to make knitted 2D shells of 3D forms. The computer simulations provided created a starting point of understanding how the knits would interact with each other.</p>\n<span style="display:block;text-align:center">\n<img src="'+n(56)+'" alt="single" width="70%" style="margin: 0 auto"/>\n*Simulation of a single knit on an industry knitting machine from [A Compiler for 3D Machine Knitting](https://www.disneyresearch.com/publication/machine-knitting-compiler/)*\n</span>\n\n<p>The needles for our machine went through multiple iterations, with each version drastically different from the previous versions.</p>\n<div class="row">\n    <div class="four columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(57)+'" alt="Junction" width="50%" style="margin: 0 auto"/>\n        *Initial Needle Design*\n        </span>\n    </div>\n    <div class="four columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(58)+'" alt="Basic" width="40%" style="margin: 0 auto"/>\n        *Needle Design 7.0*\n        </span>\n    </div>\n    <div class="four columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(59)+'" alt="Basic" width="70%" style="margin: 0 auto"/>\n        *Final Version*\n        </span>\n    </div>\n</div>\n\n<p>The final needle version required minimal custom parts and instead relied upon off-the-shelf 0.125" and 0.25" diameter aluminum rods nested in one another. The hooks and pushers were 3D printed and manually fitted onto the pipes using force, glue, and rolled-up masking tape. The outer and inner components were each driven by rack-and-pinion mechanism with a motor module. Each module had an SG90 servo motor, which were not only small but also cheap, meaning that each needle could be driven by two motors.</p>\n<p>Each row would have in total 5 different needles, meaning that there would have to be a total of 10 servo motors driven. The end goal was to eventually have an entire series of these 5 needle rows to built.</p>\n<span style="display:block;text-align:center">\n<img src="'+n(60)+'" alt="Label" width="75%" style="margin: 0 auto"/>\n</span>\n\n<h3 id="making-the-knits">Making the Knits</h3>\n<p>With all these pieces, perhaps the most difficult part of the project was programming the movement of the machine. In most other knitting machines which make knits in two dimensions, this is simpler as the yarn is relatively restricted in where it can go and any knot is pulled either on the left or the right. However, in three dimensions where a single knot can have tension coming from six different sides, it\'s incredibly difficult to accurately predict how the yarn will behave when something is done to it. </p>\n<p>After building a unit version of the needle, I made a sequence of motions to create knits by hand and the actuated needle, which you can see below:</p>\n<span style="display:block;text-align:center">\n<img src="'+n(61)+'" alt="Label" width="75%" style="margin: 0 auto"/>\n*Looping by hand*\n</span>\n\n<p>These motions were turned into the 4 separate steps you see below, which formed the basis of the ultimate sequence for creating knits.</p>\n<span style="display:block;text-align:center">\n<img src="'+n(62)+'" alt="Label" width="100%" style="margin: 0 auto"/>\n*Steps to create a knit*\n</span>\n\n<p>However, translating the steps to machine movement was incredibly challenging. Because the XY bed was built using off-the-shelf components meant for 3D printers, the code driving the machine was built off of <a href="https://www.repetier.com/">Repetier</a>, an existing Arduino-based firmware. That meant that the machine could be moved through gcode, the language used for most existing 3D printers and CNC machines. However, there needed to be a couple modifications to make the firmware work with the motion.</p>\n<table>\n<thead>\n<tr>\n<th>Command</th>\n<th>Original Definition</th>\n<th>Modified Definition</th>\n<th>Usage</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>L</code></td>\n<td>No <code>L</code> defined in Repetier</td>\n<td>Selects a needle to be actuated</td>\n<td><code>L&lt;index of desired needle&gt;</code></td>\n</tr>\n<tr>\n<td><code>E</code></td>\n<td>Length of material to be extruded</td>\n<td>Distance that the pusher moves (in mm)</td>\n<td><code>E&lt;desired distance&gt;</code></td>\n</tr>\n<tr>\n<td><code>Z</code></td>\n<td>Distance a 3D printer bed goes in Z-direction</td>\n<td>Distance the hook moves (in mm)</td>\n<td><code>Z&lt;desired distance&gt;</code></td>\n</tr>\n<tr>\n<td><code>F</code></td>\n<td>Feed rate for extruder</td>\n<td>Speed at which the machine moved</td>\n<td><code>F&lt;desired speed&gt;</code></td>\n</tr>\n</tbody></table>\n<p>Each new command was added or edited in the Commands.cpp file of the Repetier firmware. A Github repo with the modified firmware along with all sorts of other related code can be found <a href="https://github.com/kevinguo344/CrochetMatic">here</a>.</p>\n<p>There were also problems ensuring that the servos, which were chosen for their inexpensive price rather than precision, could perform the repicate the exact motion from needle to needle reliably. The solution was to exaggerate the movements of the needle to ensure that each motion would complete its requisite task.</p>\n<span style="display:block;text-align:center">\n<img src="'+n(63)+'" alt="Label" width="75%" style="margin: 0 auto"/>\n*An early version of the five needle row. Even though the needles are programmed to move identically, the actual movements are far from identical.*\n</span>\n\n<p>In order to plan for how the needle would move, I used the CAM function built into Fusion360 with the simulated CAM tool as a stand-in for the needle, a fixed tube as analog for where the yarn was extruded from, and 2 tilted boxes representing the pushing brushes. </p>\n<span style="display:block;text-align:center">\n<img src="'+n(64)+'" alt="Label" width="75%" style="margin: 0 auto"/>\n*Simulating needle movement in Fusion360*\n</span>\n\n<p>With the toolpaths set, I could output a G-code file from Fusion360, which after further editing and modification, worked with the machine. And all the changes paid off when at the end of May 2018, I was able to make the machine knit a 5-needle wide scarf (almost) entirely without human intervention.</p>\n<div class="row">\n    <div class="seven columns video-responsive">\n        <iframe width="560" height="315" src="https://drive.google.com/file/d/1NX24JxTp0RCihOpacNhDnv6LlEIOh0n9/preview"></iframe>\n    </div>\n    <div class="five columns" style="display:block;text-align:center">\n    <img src="'+n(65)+'" alt="Label" width="100%" style="margin: 0 auto"/>\n*The result of a year of work: a scarf*\n    </div>\n</div>\n\n<p>To get to this point required months of work, experimentation and false starts and for CrochetMatic to fully achieve the initial vision of fully volumetric 3D-knitting will require more work. Fortunately, it\'s currently in the competent hands of <a href="http://www.xiaoxiangma.ml/">Xiaoxiang Ma</a>, <a href="https://github.com/aliciaxw">Alicia Wang</a>, and <a href="http://amritkwatra.com/">Amrit Kwatra</a>.</p>\n<p>To see the firmware for CrochetMatic, checkout the repository <a href="https://github.com/kevinguo344/CrochetMatic">here</a>.</p>\n<h3 id="the-end">The End</h3>\n'},function(e,t,n){e.exports=n.p+"static/media/crochetmatic.e3c7114f.png"},function(e,t,n){e.exports=n.p+"static/media/voxel-single.6c3dfa0d.jpg"},function(e,t,n){e.exports=n.p+"static/media/basic.83933b43.png"},function(e,t,n){e.exports=n.p+"static/media/voxel-double.4f8888e8.jpg"},function(e,t,n){e.exports=n.p+"static/media/junction.1229a3d1.png"},function(e,t,n){e.exports=n.p+"static/media/single_layer.edb51949.gif"},function(e,t,n){e.exports=n.p+"static/media/multiple_layers.bdf4c92f.gif"},function(e,t,n){e.exports=n.p+"static/media/real_prism.4c16cf18.jpg"},function(e,t,n){e.exports=n.p+"static/media/part-overview.bc6eefb7.svg"},function(e,t,n){e.exports=n.p+"static/media/computer_sim.2cf7d002.gif"},function(e,t,n){e.exports=n.p+"static/media/first_version.964d0958.svg"},function(e,t,n){e.exports=n.p+"static/media/next_version.11019e1b.svg"},function(e,t,n){e.exports=n.p+"static/media/final_version.5c8de141.svg"},function(e,t,n){e.exports=n.p+"static/media/needle-parts.bbc1f3b6.svg"},function(e,t,n){e.exports=n.p+"static/media/loop-by-hand.c2db0d23.gif"},function(e,t,n){e.exports=n.p+"static/media/steps.10dad601.svg"},function(e,t,n){e.exports=n.p+"static/media/row.b33190b9.gif"},function(e,t,n){e.exports=n.p+"static/media/CAM-trace.cfbadaf6.gif"},function(e,t,n){e.exports=n.p+"static/media/scarf.12096cd6.png"},function(e,t){e.exports='<h3 id="distopia">Distopia</h3>\n<h6 id="august-2018-december-2018">August 2018 - December 2018</h6>\n<h5 id="people-matt-law-kevin-guo-">People: Matt Law, <strong>Kevin Guo</strong>,</h5>\n<p>Distopia is an offshoot of the <a href="http://hrc2.io/projects/Collaborative-Design">Design Assistant project</a> at Prof. Guy Hoffman\'s <a href="http://hrc2.io/">Human-Robot Collaboration &amp; Companionship Lab</a>. The goal of Distopia is to build a robotic design assistant that would facilitate the creation of better, fairer voting districts.</p>\n<h3 id="why-we-did-it">Why We Did It</h3>\n<p>In America, Congressional voting districts are determined every 10 years after the US Census. However, drawing the boundaries for these districts are incredibly hard and can be subject to all sorts of manipulation, like gerrymandering. But while an unfair district can be easy to spot, it\'s hard to say what a fair district is.</p>\n<p>The law dictates that each district in a state must have roughly the same population and must be continuous (they can&#39;t be made up of separate pieces), but beyond that doesn\'t provide any other guidelines. There are also other</p>\n'},function(e,t,n){e.exports='<h3 id="communit">communIT</h3>\n<h6 id="january-2019-present">January 2019 - Present</h6>\n<h5 id="people-kevin-guo-carlos-aguiar-alex-zhu-keith-green">People: <strong>Kevin Guo</strong>, Carlos Aguiar, Alex Zhu, Keith Green</h5>\n<span style="display:block;text-align:center">\n<img src="'+n(68)+'" width="90%" style="margin: 0 auto"/>\n*A rendering of communIT*\n</span>\n\n<p>As part of my Master of Engineering (MEng) in Mechanical Engineering, I will be working on communIT, a project of Prof. Keith Green\'s <a href="https://arl.human.cornell.edu/">Architectural Robotics Lab (ARL)</a>. transFORM is a room-scaled, kirigami-inspired robotic environment for public spaces. For more information, go to the <a href="https://arl.human.cornell.edu/research-transFORM.html">ARL page on transFORM</a>.</p>\n<h3 id="background">Background</h3>\n<p>I\'ve always been interested in architecture and for my <a href="https://www.engineering.cornell.edu/students/undergraduate-students/entrepreneurial-options-undergrad-students/kessler-fellows-program">Kessler Fellowship</a> the summer of my junior year, I interned at <a href="https://oriliving.com/">Ori Inc</a>, an MIT Media Lab spinoff building robotic furniture for urban apartments. During my time at Ori, I became increasingly interested in applying architectural robotics to the public realm. After all, if we could make apartments responsive, couldn\'t we do the same for a public plaza that was used by all walks of life? That\'s why I wanted to work on communIT when I returned to Cornell.</p>\n<h3 id="user-research-concept-design">User Research &amp; Concept Design</h3>\n<span style="display:block;text-align:center">\n<img src="'+n(69)+'" width="90%" style="margin: 0 auto"/>\n*Carlos with the original version of communIT at MVR Commons*\n</span>\n\n<p>The previous version of communIT was an non-functional full-scale prototype that was made out of particle board and cardboard with velcro squares attached throughout the sides. Carlos Aguiar conducted user studies with this protoype over a course of 5 weeks in which pairs of students at Cornell would &quot;co-design&quot; by reconfiguring the prototype, attach &quot;peripherals,&quot; and act out the activities they\'d want do with an actual working communIT. The point of these exercises was to see what people would use communIT for, what features they wanted in a working version, and what design shortcomings were present with the existing version.</p>\n<p>These findings were then sorted into 17 specific use cases and 6 overall themes:</p>\n<ol>\n<li>Reading</li>\n<li>Presenting</li>\n<li>Office Work</li>\n<li>Relaxing/Watching</li>\n<li>Playing</li>\n<li>Exhibiting Artwork</li>\n</ol>\n<p>Taking the findings and use cases, I developed scenarios for each of the use cases, detailing how a user might use communIT in each of the configurations and how they might best interact with the panels (touch screen, web app, gesture-based interface, etc.) in order to inform both the types of configurations were most useful and give an idea of the technologies we&#39;d need to integrate in the final design.</p>\n<span style="display:block;text-align:center">\n<img src="'+n(70)+'" width="90%" style="margin: 0 auto"/>\n*All design cases and user scenarios*\n</span>\n\n<p>With all the cases developed and scenarios, Carlos spent of the semester developing the new version of communIT with feedback from me and the rest of the team.</p>\n<div class="row">\n    <div class="six columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(71)+'" alt="Basic" width="100%" style="margin: 0 auto"/>\n        *Scale model of initial version of communIT*\n        </span>\n    </div>\n    <div class="six columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(72)+'" alt="Basic" width="100%" style="margin: 0 auto"/>\n        *Scale model of another proposed design for communIT*\n        </span>\n    </div>\n</div>\n\n<span style="display:block;text-align:center">\n<img src="'+n(73)+'" width="90%" style="margin: 0 auto"/>\n*Scale model of final concept design for communIT*\n</span>\n\n<h3 id="assembly-design-manufacturing">Assembly Design &amp; Manufacturing</h3>\n<p>With the concept for communIT completed, I took over the rest of the design process, mainly focusing on manufacturability and mechatronic applications. The first consideration was how to deal with the very practical weight and torque requirements that would be needed to power each of the panels. An earlier proposal to make the panels out of MDF and acrylic would have proven to be too heavy to either move with motors that were within our budget and unsafe in case of a mechanical failure. Instead, we settled on a &quot;sandwich&quot; of two 1&quot; thick CNC\'d Polystyrene foam separated by 0.5&quot; plastic spacer with 0.06&quot; thick translucent laser cut acrylic on either side.</p>\n<p>The finalized design of communIT stands 76 inches (193 cm) tall and 125 inches (317.5 cm) wide. This size was chosen as it was taller than an adult man but not so tall as to feel completely overwhelming. The artifact is made of 8 panels, ranging in size from 30 in by 20 in with the smallest panel to 77 inch by 45 inch for the largest panel.</p>\n<span style="display:block;text-align:center">\n<img src="'+n(74)+'" width="90%" style="margin: 0 auto"/>\n*Exploded render of the panel assembly*\n</span>\n\n<div class="row">\n    <div class="six columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(75)+'" alt="Basic" width="100%" style="margin: 0 auto"/>\n        *Two panels closed with acrylic surface*\n        </span>\n    </div>\n    <div class="six columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(76)+'" alt="Basic" width="100%" style="margin: 0 auto"/>\n        *Two panels opened with LED grooves and strips *\n        </span>\n    </div>\n</div>\n\n<span style="display:block;text-align:center">\n<img src="'+n(77)+'" width="90%" style="margin: 0 auto"/>\n*A test panel with embedded LEDs being tested.*\n</span>\n\n<h4 id="assembly-is-still-in-progress-and-this-page-will-be-updated-as-work-progresses-stay-tuned-">Assembly is still in progress and this page will be updated as work progresses. Stay Tuned!</h4>\n'},function(e,t,n){e.exports=n.p+"static/media/communIT.d1069789.png"},function(e,t,n){e.exports=n.p+"static/media/original_communit.c902b6b3.png"},function(e,t,n){e.exports=n.p+"static/media/design_cases_cropped.1509f057.png"},function(e,t,n){e.exports=n.p+"static/media/version1.47f10794.png"},function(e,t,n){e.exports=n.p+"static/media/version2.cd1b9f6a.png"},function(e,t,n){e.exports=n.p+"static/media/model.e5730a2e.png"},function(e,t,n){e.exports=n.p+"static/media/panel_explode.2d3b2c32.png"},function(e,t,n){e.exports=n.p+"static/media/panel_closed.5b0bdbfd.png"},function(e,t,n){e.exports=n.p+"static/media/panel_open.98dc8e65.png"},function(e,t,n){e.exports=n.p+"static/media/light_test_temporary.d20c7228.png"},function(e,t,n){e.exports='<h3 id="cera-ceramic-extruding-robot-arm">CERA: Ceramic Extruding Robot Arm</h3>\n<h6 id="january-2019-present">January 2019 - Present</h6>\n<h5 id="people-kevin-guo-madeleine-eggers-karolina-piorko-veronika-varga-jenny-sabin">People: <strong>Kevin Guo</strong>, Madeleine Eggers, Karolina Piorko, Veronika Varga, Jenny Sabin</h5>\n<span style="display:block;text-align:center">\n<img src="'+n(79)+'" width="90%" style="margin: 0 auto"/>\n*CERA fully assembled*\n</span>\n\n<p>For Spring 2019, I took <a href="http://www.jennysabin.com/">Prof. Jenny Sabin\'s</a> research seminar in Matter Design Computation. As part of the seminar, I worked on a brand-new extruder system for the lab\'s Sulla robotic arm, a system we call CERA (Ceramic Extruding Robot Arm). I continued work on it through the Summer and into Fall 2019.</p>\n<h3 id="background">Background</h3>\n<p>In the past, the Lab used a pneumatic ceramic extruder system used for <a href="https://static1.squarespace.com/static/5783b6f903596e5098f3fce8/t/5c3774c7352f539da89eceb8/1547138275044/Robosense+2.0.pdf">RoboSense 2.0</a>. This system had a few issues; the pneumatics were independent of the robot so there was no coordination between the robot and the extruder. Also, pneumatic controls were very coarse, only allowing for a change in pressure. For the next iteration of RoboSense, we wanted to make a fabrication method that would allow for the construction of fine detailed objects such as <a href="http://www.jennysabin.com/polybrick/">PolyBrick</a> in an architectural scale.</p>\n<h3 id="design">Design</h3>\n<span style="display:block;text-align:center">\n<img src="'+n(80)+'" alt="Basic" width="75%" style="margin: 0 auto"/>\n*Exploded view of CERA*\n</span>\n<span style="display:block;text-align:center">\n<img src="'+n(81)+'" alt="Basic" width="75%" style="margin: 0 auto"/>\n*Cutaway diagram of CERA on robot arm*\n</span>\n\n<p>The overall design of CERA is centered around a 2ft long 4.5in diameter aluminum tube with a plunger inside. The plunger is attached to a leadscrew, which itself is driven by a worm gearbox. This gearbox is powered by a 1712oz-in NEMA34 Closed Loop Stepper Motor.</p>\n<h3 id="mechatronics">Mechatronics</h3>\n<h4 id="motor">Motor</h4>\n<span style="display:block;text-align:center">\n<img src="'+n(82)+'" width="75%" style="margin: 0 auto"/>\n*1712oz-in NEMA34 Closed Loop Stepper Motor*\n</span>\n\n<p>One of the first decisions that had to be made was which motor to use for the extruder. A stepper motor powered extruder was attempted before in the lab but had to be abandoned as discrepancies between the motor\'s reported and actual position made it virtually impossible use accurately. That ultimately blocked progress on RoboSense and forced it to be shelving until I arrived at the lab.</p>\n<p>I stuck with using a stepper motor as I had used them extensively in previous roles and knew that a stepper would have the requisite torque to push clay through a tube. To deal with problems with positioning, I chose a closed-loop stepper motor system, a stepper motor with a built-in encoder that corrects for any discrepancies in motor position. </p>\n<h4 id="machina">Machina</h4>\n<p>To command the robot, we decided upon <a href="https://github.com/RobotExMachina">Machina</a>, an open-source framework for robots that allows for real-time control and feedback. This allowed for us to control the robot directly from either a PC Desktop or from Grasshopper without the need for predefining a sequence of actions or using RobotStudio, ABB\'s proprietary programming software for its robots. It also had a large set of commands that allow for a rich set of functionality including for digital I/O communication detailed below. </p>\n<h4 id="digital-i-o-communication">Digital I/O Communication</h4>\n<span style="display:block;text-align:center">\n<img src="'+n(83)+'" width="75%" style="margin: 0 auto"/>\n*Inside of an ABB IRC5*\n</span>\n\n<p>The next step was figuring out how to communicate between Grasshopper, the robot, and CERA all at once. The initial communication system involved using Firefly, a Grasshopper plugin for microcontrollers, to send Serial messages over a very long USB cable in this format: <code>Steps/Pulse Width</code>. So the Serial message <code>500/250</code> would be read by the Arduino as move 500 steps counterclockwise with a 250 \xb5s delay in between pulses.</p>\n<p>While this solution was simple to implement, it didn\'t solve the inherent separation between robot movement and extruder action that would inevitably create issues with fabrication down the road. There had to be a new system that allowed for native communication the robot to control the extruder and any other components attached.</p>\n<p>After some searching, I learned that the ABB IRC5 robot controller that we were using had a I/O module built in called an DSQC 652. More importantly, the DSQC 652 had 16 digital outputs. A digital output is only capable of spitting out a 1 or a 0, but that would be enough.</p>\n<p>Two digital outputs from the ABB\'s I/O module are wired from the inside of the IRC5 controller, past a barrier wall, up the robot arm, and onto the mounting plate with the Arduino board. One digital output dictates which direction the stepper motor would turn (On means clockwise, Off means counter-clockwise), which dictates whether the extruder piston goes forward or back. The other digital output is an On/Off switch for the stepper motor; as long as the output was On, the motor would make another &quot;step&quot; and continue rotating.</p>\n<p>These outputs made it very easy to synchronize actions between robot and extruder. As all commands went through Machina and therefore the robot, the sequence guaranteed extrusion concurrent with robot movement.</p>\n<h5 id="example-command-sequence">Example Command Sequence</h5>\n<table>\n<thead>\n<tr>\n<th>Command</th>\n<th>What it does</th>\n</tr>\n</thead>\n<tbody><tr>\n<td><code>digitalWrite(DO10_2, True)</code></td>\n<td>Sets direction of motor to move plunger forward</td>\n</tr>\n<tr>\n<td><code>digitalWrite(DO10_1, True)</code></td>\n<td>Turns on stepper motor</td>\n</tr>\n<tr>\n<td><code>wait(&lt;time in milliseconds&gt;)</code></td>\n<td>Gives extruder some time to &quot;prime&quot;</td>\n</tr>\n<tr>\n<td><code>move(&lt;some vector&gt;)</code></td>\n<td>Moves robot a certain amount</td>\n</tr>\n<tr>\n<td><code>digitalWrite(DO10_1, False)</code></td>\n<td>Turns off stepper motor</td>\n</tr>\n</tbody></table>\n<div class="row">\n    <div class="five columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(84)+'" width="100%" style="margin: 0 auto"/>\n        *CERA extruding ceramic for a "line test"*\n        </span>\n    </div>\n    <div class="seven columns" style="display:block;text-align:center">\n        <span style="display:block;text-align:center">\n        <img src="'+n(85)+'" alt="Basic" width="100%" style="margin: 0 auto"/>\n        *Full results of first CERA line test*\n        </span>\n    </div>\n</div>\n\n<h3 id="adapative-print">Adapative Print</h3>\n<p>Adaptive print is a new part of RoboSense 3.0 that incorporates work done <a href="http://www.ttistengteng.com/PicDetail.aspx?id=489">previously</a> and will involve surface reconstruction from a Kinect.</p>\n<h4 id="this-page-will-be-updated-with-more-information-as-work-progresses-stay-tuned-">This page will be updated with more information as work progresses. Stay Tuned!</h4>\n'},function(e,t,n){e.exports=n.p+"static/media/cera.73c8ca81.jpg"},function(e,t,n){e.exports=n.p+"static/media/drawing_extruder1.bf1b708c.png"},function(e,t,n){e.exports=n.p+"static/media/drawing_cutaway.e6cb4840.png"},function(e,t,n){e.exports=n.p+"static/media/motors.172ae879.png"},function(e,t,n){e.exports=n.p+"static/media/abb-inside.f6d33201.jpg"},function(e,t,n){e.exports=n.p+"static/media/line-test.06d74e13.png"},function(e,t,n){e.exports=n.p+"static/media/line-test-full.cfada91e.jpg"},function(e,t,n){e.exports='<h3 id="cuberpillar">Cuberpillar</h3>\n<h6 id="february-2018">February 2018</h6>\n<div class="row">\n    <div class="ten columns offset-by-one" style="display:block;text-align:center">\n        <img src="'+n(87)+'" alt="Cuberpillar" width="100%" style="margin: 0 auto"/>\n    </div>\n</div>\n\n<div class="row">\n    <div class="eight columns offset-by-two video-responsive">\n        <iframe width="560" height="315" src="https://www.youtube.com/embed/7CXaytbcfXY" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>\n    </div>\n</div>\n\n<p>Cuberpillar was a project for <a href="https://classes.cornell.edu/browse/roster/SP18/class/DEA/4210">DEA 4210 Interaction Design Studio</a>. The prompt for this project was to build a box of wonder. Given how vague that was, I decided to create a box that didn\'t contain a wondrous experience, but instead acted in an unexpected or wondrous manner.</p>\n<h3 id="mechanism">Mechanism</h3>\n<p>For that I decided to use a continuum mechanism, a mechanism in which discrete segments are linked and can create organic movements. However, most continuum robots are long and snaking and are attached to a fixed base (like the one below)</p>\n<div class="row">\n    <div class="eight columns offset-by-two" style="display:block;text-align:center">\n        <img src="'+n(88)+'" alt="continuum" width="100%" style="margin: 0 auto"/>\n        *A very typical continuum robot*\n    </div>\n</div>\n\n<p>An example of a self-supporting cube or rectangular continuum robot seems to not exist in either the scientific literature or in any of my frantic Google searches. So the process of designing the robot became a long series of guess and check with multiple different sizes, flexible pipes, and mechanics till I finally arrived to the following cardboard prototype.</p>\n<div class="row">\n    <div class="eight columns offset-by-two" style="display:block;text-align:center">\n        <img src="'+n(89)+'" alt="cardboard" width="100%" style="margin: 0 auto"/>\n        *Special thanks to the local Lowes, zip-ties, and super glue for making this cardboard prototype possible*\n    </div>\n</div>\n\n<p>Each side of every square plate has fishing line strung to the neighboring plate. At either end, a servo-driven pulley pulls at opposing sides of the plates, creating a &quot;crawling&quot; motion.</p>\n<div class="row">\n    <div class="eight columns offset-by-two" style="display:block;text-align:center">\n        <img src="'+n(90)+'" alt="top view" width="100%" style="margin: 0 auto"/>\n        *Top view of the box*\n    </div>\n</div>\n\n<p>Each side of every square plate has fishing line strung to the neighboring plate. At either end, a servo-driven pulley pulls at opposing sides of the plates, creating a &quot;crawling&quot; motion. To cloak the &quot;guts&quot; of the box and add some structural support, I added patterned laser-cut fabric sheets along the sides.</p>\n<h3 id="reactions">Reactions</h3>\n<p>Given that the box was meant to resemble a creature, one that acted entirely by itself with little to no input from a user, there was no real &quot;user experience&quot; per say. But as I was filming the box in action around the 2nd floor of Gates Hall for the video at the top of the page, I was receiving surprisingly strong reactions from those around it. Some reacted positively, calling it &quot;cute.&quot; Some were surprisingly negative, with one of the PhDs saying &quot;I have so much contempt for this thing,&quot; as it crawled along his desk. Another, when seeing that it often had trouble moving forward declared &quot;I hate it because it reminds me of myself: writhing around but unable to go anywhere.&quot;</p>\n<p>These reactions to the box, even though it wasn\'t meant to be &quot;interactive&quot; the way an app or website does, has made me think about the possibilities of robotics in art. Perhaps, a robot, more than being a simple tool, could be used to evoke questions about our nature and our inherent humanity. This I\'d like to explore further.</p>\n<p>If you\'re interested in the more technical details about the project, checkout the documentation I submitted for the assigmnent <a href="https://drive.google.com/file/d/19Vr0eK3bR2Fvb-IcK58ZRGgLr12up9rf/view?usp=sharing">here</a>.</p>\n'},function(e,t,n){e.exports=n.p+"static/media/cuberpillar_cover.6cde9323.gif"},function(e,t,n){e.exports=n.p+"static/media/example_continuum.9761d648.jpg"},function(e,t,n){e.exports=n.p+"static/media/cardboard_prototype.c993dcfe.JPG"},function(e,t,n){e.exports=n.p+"static/media/cuberpillar_top.fc8ba913.JPG"},function(e,t,n){e.exports='<h3 id="ocularmd">OcularMD</h3>\n<h6 id="november-2016">November 2016</h6>\n<p>OcularMD started as a company for Cornell\u2019s 3 Day Startup program where students found a startups, and present a final pitch in 3 days over one weekend. OcularMD was an app that could quickly diagnose diabetic retinopathy, a potentially blinding eye disease. Unlike previous works, I had to start completely from scratch, and I was able to make a corporate identity that was distinct and identifiable. OcularMD ended up wining 3 Day Startups\\\u2019 Big Red Venture Fund Seed Money Award, beating out four other startups founded at the same time.</p>\n<div class="row">\n    <div class="eight columns offset-by-two" style="display:block;text-align:center">\n        <img src="'+n(92)+'" alt="logomark" width="100%" style="margin: 0 auto"/>\n        *The logomark had to be indicative of both a high-tech startup and a trusted medical company.*\n    </div>\n</div>\n\n<div class="row">\n    <div class="five columns" style="display:block;text-align:center">\n        <img src="'+n(93)+'" alt="logomark" width="100%" style="margin: 0 auto"/>\n        *The main part of OcularMD\u2019s branding is the Spotlight, which symbolizes the company\u2019s dedication to magnifying and illuminating the unknown.*\n    </div>\n    <div class="seven columns" style="display:block;text-align:center">\n        <img src="'+n(94)+'" alt="logomark progress" width="100%" style="margin: 0 auto"/>\n        *The different iterations of the Spotlight over the 3 days.*\n    </div>\n</div>\n\n<div class="row">\n    <div class="three columns offset-by-one" style="display:block;text-align:center">\n        <img src="'+n(95)+'" alt="launch screen" width="100%" style="margin: 0 auto"/>\n    </div>\n    <div class="three columns offset-by-one" style="display:block;text-align:center">\n        <img src="'+n(96)+'" alt="logomark" width="100%" style="margin: 0 auto"/>\n    </div>\n    <div class="three columns offset-by-one" style="display:block;text-align:center">\n        <img src="'+n(97)+'" alt="logomark" width="100%" style="margin: 0 auto"/>\n    </div>\n    <div class="twelve columns" style="display:block;text-align:center">\n        *The UI for the application is meant to be as straight-forward as possible by putting users through an easy step-by-step process. At the end, they receive a display of the results.*\n    </div>\n</div>\n\n<div class="row">\n    <div class="ten columns offset-by-one video-responsive" style="display:block;text-align:center">\n        <iframe src="https://drive.google.com/file/d/1wRO5271vEMA4HX91rrzcAhK8Nl_pJgIw/preview" width="640" height="480"></iframe>\n        *Pitch deck used during the 3 Day Startup Pitch competition.*\n    </div>\n\n</div>'},function(e,t,n){e.exports=n.p+"static/media/ocularmd_logomark.6858bb1b.png"},function(e,t,n){e.exports=n.p+"static/media/spotlight.5eda29fd.png"},function(e,t,n){e.exports=n.p+"static/media/progress.92b1f79d.png"},function(e,t,n){e.exports=n.p+"static/media/iphone_1.252b0026.png"},function(e,t,n){e.exports=n.p+"static/media/iphone_2.4d383fb2.png"},function(e,t,n){e.exports=n.p+"static/media/iphone_3.626b508e.png"},function(e,t,n){e.exports='<h3 id="cornell-international-affairs-society">Cornell International Affairs Society</h3>\n<h6 id="december-2016-november-2017">December 2016 - November 2017</h6>\n<p>As Director of Tech of the Cornell International Affairs Society\\\u2019s college Model UN conference, I decided to change the messy branding of years past with a new consistent identity. Included in that was a cleaning up of the existing logo, and the creation of multiple new assets and a single standard for all printed material during the conference.</p>\n<div class="row">\n    <div class="twelve columns" style="display:block;text-align:center">\n        <img src="'+n(99)+'" alt="final motif" width="100%" style="margin: 0 auto"/>\n        *The final logo and motif for CIAC*\n    </div>\n</div>\n\n<p>Normally, Director of Technology is a caretaker role, ensuring what was made previous years is updated for the current year\'s conference. But I wasn\'t content to just be caretaker. Instead, I evaluated the state of the conference\'s branding and found a few things. In previous years, the branding used seemed confused, inconsistent, or downright bad.</p>\n<div class="row">\n    <div class="four columns" style="display:block;text-align:center">\n        <img src="'+n(100)+'" alt="final motif" width="100%" style="margin: 0 auto"/>\n    </div>\n    <div class="four columns" style="display:block;text-align:center">\n        <img src="'+n(101)+'" alt="final motif" width="100%" style="margin: 0 auto"/>\n    </div>\n    <div class="four columns" style="display:block;text-align:center">\n        <img src="'+n(102)+'" alt="final motif" width="100%" style="margin: 0 auto"/>\n    </div>\n    <div class="twelve columns" style="display:block;text-align:center">\n        *Examples of previous years\\\' branding work*\n    </div>\n</div>\n\n<p>We were a relatively new conference, dwarfed by others hosted by the likes of Yale, Harvard, and Penn, and so our image was important to how we did. If anything was going to sink us, it shouldn\'t be bad design. After cleaning up and vectorizing the main CIAC shield logo, I developed the motif of the ribbon. The ribbon could symbolize anything from gift wrapping to a sash, which was furthered by the pseudo-heraldic shield that was in the new logo. Either way, any document with this motif on it would make the reader feel special, as if they were opening a gift or receiving a noble reward. It was applied to all the documents distributed to delegates during the conference along with packets sent to all potential sponsors.</p>\n<div class="row">\n    <div class="ten columns offset-by-one" style="display:block;text-align:center">\n        <img src="'+n(103)+'" alt="covers" width="100%" style="margin: 0 auto"/>\n        *Documents from CIAC VII showing off the ribbon motif*\n    </div>\n</div>\n\n<p>In order to preserve these changes and maintain consistency, I created a style guide for any future directors of tech who will need to make new documents and assets.</p>\n<div class="row">\n    <div class="six columns" style="display:block;text-align:center">\n        <img src="'+n(104)+'" alt="styling" width="100%" style="margin: 0 auto"/>\n    </div>\n    <div class="six columns" style="display:block;text-align:center">\n        <img src="'+n(105)+'" alt="relative positioning" width="100%" style="margin: 0 auto"/>\n    </div>\n</div>'},function(e,t,n){e.exports=n.p+"static/media/ciac banner.7021427e.png"},function(e,t,n){e.exports=n.p+"static/media/old_ciac1.795d4368.jpg"},function(e,t,n){e.exports=n.p+"static/media/old_ciac2.ef750e00.jpg"},function(e,t,n){e.exports=n.p+"static/media/old_ciac3.9f0a7d40.jpg"},function(e,t,n){e.exports=n.p+"static/media/ciac_covers.f91ce21a.png"},function(e,t,n){e.exports=n.p+"static/media/styles.d02f5d0d.png"},function(e,t,n){e.exports=n.p+"static/media/positioning.2f940739.png"},function(e,t,n){e.exports='<h3 id="life-changing-labs">Life Changing Labs</h3>\n<h6 id="june-2016-august-2019">June 2016 - August 2019</h6>\n<p>I worked at Life Changing Labs\u2019 Summer Incubator Program where I did design work for a few startups and LCL itself. Because of the nature of these startups, some of my work was placed under a non-disclosure agreement. However I can show some of my work for LCL specifically. Included in that work was promotional material for the cancelled Innovators Fair, an event for startups, student organizations, and individuals to display their ideas. A pitch competition for $3000 was supposed to occur at the end of the Fair.</p>\n<div class="row">\n    <div class="six columns" style="display:block;text-align:center">\n        <img src="'+n(107)+'" alt="styling" width="75%" style="margin: 0 auto"/>\n        *An early version of the poster: I started with a general theme of space. The above poster was meant to represent illumination of a previously hidden constellation of ideas. While this design went unused, the spotlight was eventually used for OcularMD\u2019s branding.*\n    </div>\n    <div class="six columns" style="display:block;text-align:center">\n        <img src="'+n(108)+'" alt="relative positioning" width="75%" style="margin: 0 auto"/>\n        *A later version of the poster: While previous version of the poster simply illuminated ideas, this version was to show their centrality, in a way empowering people with ideas to display and share them.*\n    </div>\n</div>\n\n'},function(e,t,n){e.exports=n.p+"static/media/lcl1.5daac559.png"},function(e,t,n){e.exports=n.p+"static/media/lcl2.0b3aada6.png"},function(e,t,n){e.exports='<h3 id="cornell-university-ems">Cornell University EMS</h3>\n<p>This was as an independent project I started after becoming fed up with the CUEMS\u2019 outdated website, logo, and overall lack of brand direction. What began as a small project to change the squad\u2019s logo spun into a larger project to change CUEMS\u2019 public image. I updated logo design to better reflect CUEMS\u2019 intended public image, build a new website, newly designed ID badge, and a new consistent set of branding material.</p>\n<div class="row">\n    <div class="six columns" style="display:block;text-align:center">\n        <img src="'+n(110)+'" alt="Crochetmatic" width="100%" style="margin: 0 auto"/>\n    </div>\n    <div class="six columns" style="display:block;text-align:center">\n        <img src="'+n(16)+'" alt="That\'s me in that pic" width="100%" style="margin: 0 auto"/>\n    </div>\n</div>\n'},function(e,t,n){e.exports=n.p+"static/media/LOGO GOOD.baca3bf0.png"},,function(e,t,n){"use strict";n.r(t);var a=n(0),i=n.n(a),o=n(17),r=n.n(o),s=(n(25),n(3)),l=n(4),c=n(6),d=n(5),h=n(7),u=(n(27),n(29),{marginTop:"25%"}),p=function(e){function t(e){var n;return Object(s.a)(this,t),(n=Object(c.a)(this,Object(d.a)(t).call(this,e))).width=n.stringToNum(n.props.width),null!=n.width?n.width+=" columns":n.width="column",n.offset=n.stringToNum(n.props.offset),null!=n.offset?n.offset=" offset-by-"+n.offset:n.offset="","true"===n.props.title&&(n.style=u),n}return Object(h.a)(t,e),Object(l.a)(t,[{key:"stringToNum",value:function(e){var t;switch(e){case"":t=null;break;case"1/2":t="half";break;case"1/3":t="one-third";break;case"2/3":t="two-thirds";break;case"1":t="one";break;case"2":t="two";break;case"3":t="three";break;case"4":t="four";break;case"5":t="five";break;case"6":t="six";break;case"7":t="seven";break;case"8":t="eight";break;case"9":t="nine";break;case"10":t="ten";break;case"11":t="eleven";break;case"12":t="twelve";break;default:t=null}return t}},{key:"render",value:function(){return i.a.createElement("div",{className:this.width+this.offset,style:this.style},this.props.children)}}]),t}(i.a.Component),m=function(e){function t(){return Object(s.a)(this,t),Object(c.a)(this,Object(d.a)(t).apply(this,arguments))}return Object(h.a)(t,e),Object(l.a)(t,[{key:"render",value:function(){return i.a.createElement("div",{className:"container"},this.props.children)}}]),t}(i.a.Component),g=function(e){function t(){return Object(s.a)(this,t),Object(c.a)(this,Object(d.a)(t).apply(this,arguments))}return Object(h.a)(t,e),Object(l.a)(t,[{key:"render",value:function(){return i.a.createElement("div",{className:"row"},this.props.children)}}]),t}(i.a.Component),f=(n(13),n(113)),w=function(e){function t(e){var n;return Object(s.a)(this,t),(n=Object(c.a)(this,Object(d.a)(t).call(this,e))).project=b[n.props.project],n.side=n.props.side,n.style={background:"linear-gradient(to bottom,"+n.project.color+","+n.project.color+"), linear-gradient(to bottom, rgba(255,255,255,0.45),rgba(255,255,255,0.45)), url("+n.project.img+")",backgroundSize:"cover"},n}return Object(h.a)(t,e),Object(l.a)(t,[{key:"render",value:function(){return i.a.createElement(f.a,{to:"/"+this.project.link},i.a.createElement(p,{width:"6"},i.a.createElement("div",{className:"titleCard "+this.side},i.a.createElement("div",{className:"titleContainer"},i.a.createElement("h2",null,this.project.title),i.a.createElement("h6",null,this.project.sub)),i.a.createElement("div",{className:"background",style:this.style}))))}}]),t}(i.a.Component),b={roma:{title:"RoMA",sub:"Interactive Fabrication in AR",link:"research/roma",img:"./assets/icons/roma.svg",color:"rgba(227,181,5,0.325)"},crochetmatic:{title:"CrochetMatic",sub:"Knitting in 3D",link:"research/crochetmatic",img:"./assets/icons/crochetmatic.svg",color:"rgba(219,80,74,0.325)"},distopia:{title:"Distopia",sub:"Build a Better Voting District",link:"research/distopia",img:"./assets/icons/distopia.svg",color:"rgba(138,201,38,0.325)"},communit:{title:"communIT",sub:"A Responsive Public Environment",link:"research/communit",img:"./assets/icons/transform.svg",color:"rgba(58,153,215,0.325)"},cera:{title:"CERA",sub:"Detailed extrusion at Architectural Scale",link:"research/cera",img:"./assets/icons/cera.svg",color:"rgba(138,201,38,0.325)"},cuberpillar:{title:"Cuberpillar",sub:"Combining the geometric and organic",link:"designs/cuberpillar",img:"./assets/icons/cuberpillar.gif",color:"rgba(255,255,255,0)"},ocularmd:{title:"OcularMD",sub:"Letting the world see again",link:"designs/ocularmd",img:"./assets/icons/ocularmd_icon.png",color:"rgba(255,255,255,0)"},ciac:{title:"CIAC VII",sub:"Bringing order to a messy brand",link:"designs/ciac",img:"./assets/icons/ciac_icon.png",color:"rgba(255,255,255,0)"},lcl:{title:"Life Changing Labs",sub:"Giving startups a new beginning",link:"designs/lcl",img:"./assets/icons/lcl_icon.png",color:"rgba(255,255,255,0)"},cornellems:{title:"Cornell EMS",sub:"Redefining an old stalwart",link:"designs/cornellems",img:"./assets/icons/roma.png",color:"rgba(255,255,255,0)"}},y=w,v=function(e){function t(){return Object(s.a)(this,t),Object(c.a)(this,Object(d.a)(t).apply(this,arguments))}return Object(h.a)(t,e),Object(l.a)(t,[{key:"render",value:function(){return i.a.createElement("div",{className:"pageView"},i.a.createElement("div",{className:"pageContainer"},this.props.children))}}]),t}(i.a.Component),k=n(14),x=n.n(k),E=function(e){function t(){return Object(s.a)(this,t),Object(c.a)(this,Object(d.a)(t).apply(this,arguments))}return Object(h.a)(t,e),Object(l.a)(t,[{key:"render",value:function(){return i.a.createElement(m,null,i.a.createElement(v,null,i.a.createElement(g,null,i.a.createElement(p,{width:"6"},i.a.createElement("h1",null,i.a.createElement("strong",null,"Hi, I'm Kevin")))),i.a.createElement(g,null,i.a.createElement(p,{width:"8"},i.a.createElement("p",null,"I'm currently a student Cornell University pursuing a Masters of Engineering in Mechanical Engineering focusing on Robotics and Product Design. My advisor is ",i.a.createElement("a",{href:"https://arl.human.cornell.edu/people_keith.htm"},"Prof. Keith Green")," of the Design + Environmental Analysis (DEA) department and I also work with ",i.a.createElement("a",{href:"http://www.jennysabin.com/"},"Prof. Jenny Sabin")," of the Architecture department. I completed my undergrad degree in Information Science, Systems, & Technology also from Cornell. "),i.a.createElement("p",null,"I'm interested in learning how technology can make design more accessible, useful, and exciting, especially in its applications to architecture and the built environment.")),i.a.createElement(p,{width:"4"},i.a.createElement("h5",null,i.a.createElement("a",{href:"https://www.linkedin.com/in/kevinlguo/"},"LinkedIn")),i.a.createElement("h5",null,i.a.createElement("a",{href:"https://drive.google.com/file/d/1A6l2PUh6bY0s7zW-LWEin3AzVglI4o_I/view?usp=sharing"},"Resume")),i.a.createElement("h5",null,"Email: kg344[at]cornell.edu")))),i.a.createElement(v,null,i.a.createElement(x.a,{minWidth:550},i.a.createElement(g,null,i.a.createElement("h2",null,i.a.createElement("strong",null,"Projects")),i.a.createElement("p",null,"My research focuses on the applications of robotics in design. Of special interest are the design and construction of interactive robotic environments and novel forms of robotic fabrication.")),i.a.createElement(g,null,i.a.createElement(y,{project:"communit",side:"left"}),i.a.createElement(y,{project:"cera",side:"left"})),i.a.createElement(g,null,i.a.createElement(y,{project:"crochetmatic",side:"right"}),i.a.createElement(y,{project:"roma",side:"right"}))),i.a.createElement(x.a,{maxWidth:550},i.a.createElement(g,null,i.a.createElement("h1",null,"Projects"),i.a.createElement("p",null,"My research focuses on the applications of robotics in design, especially in architecture. Of special interest are the design and construction of interactive robotic environments and novel forms of robotic fabrication.")),i.a.createElement(g,null,i.a.createElement(y,{project:"communit",side:"right"}),i.a.createElement(y,{project:"cera",side:"left"})),i.a.createElement(g,null,i.a.createElement(y,{project:"crochetmatic",side:"right"}),i.a.createElement(y,{project:"roma",side:"left"})))))}}]),t}(a.Component),I=function(e){function t(){return Object(s.a)(this,t),Object(c.a)(this,Object(d.a)(t).apply(this,arguments))}return Object(h.a)(t,e),Object(l.a)(t,[{key:"render",value:function(){return i.a.createElement(g,null,i.a.createElement(p,{width:"1"},i.a.createElement(f.a,{to:"/"},i.a.createElement("h2",null,i.a.createElement("i",{className:"fas fa-angle-double-left"})))),i.a.createElement(p,{width:"11"},i.a.createElement("h2",null,"Kevin Guo")))}}]),t}(i.a.Component),A=function(e){function t(){return Object(s.a)(this,t),Object(c.a)(this,Object(d.a)(t).apply(this,arguments))}return Object(h.a)(t,e),Object(l.a)(t,[{key:"render",value:function(){return i.a.createElement(m,null,i.a.createElement(I,null),i.a.createElement(g,null,i.a.createElement(p,{className:"projects",width:"12"},this.props.children)))}}]),t}(a.Component),C=n(8),j=n(34),T=n(46),M=n(66),D=n(67),O=n(78),S=function(){return i.a.createElement(A,null,i.a.createElement(C.a,null,j))},R=function(){return i.a.createElement(A,null,i.a.createElement(C.a,null,T))},q=function(){return i.a.createElement(A,null,i.a.createElement(C.a,null,M))},P=function(){return i.a.createElement(A,null,i.a.createElement(C.a,null,D))},B=function(){return i.a.createElement(A,null,i.a.createElement(C.a,null,O))},L=n(86),_=n(91),F=n(98),W=n(106),G=n(109),N=function(){return i.a.createElement(A,null,i.a.createElement(C.a,null,L))},K=function(){return i.a.createElement(A,null,i.a.createElement(C.a,null,_))},J=function(){return i.a.createElement(A,null,i.a.createElement(C.a,null,F))},z=function(){return i.a.createElement(A,null,i.a.createElement(C.a,null,W))},H=function(){return i.a.createElement(A,null,i.a.createElement(C.a,null,G))},U=n(115),V=n(114),Y=function(e){function t(){return Object(s.a)(this,t),Object(c.a)(this,Object(d.a)(t).apply(this,arguments))}return Object(h.a)(t,e),Object(l.a)(t,[{key:"render",value:function(){return i.a.createElement(U.a,null,i.a.createElement("div",null,i.a.createElement(V.a,{exact:!0,path:"/",render:function(e){return i.a.createElement(E,{routerProps:e})}}),i.a.createElement(V.a,{exact:!0,path:"/research/roma",render:function(e){return i.a.createElement(S,{routerProps:e})}}),i.a.createElement(V.a,{exact:!0,path:"/research/crochetmatic",render:function(e){return i.a.createElement(R,{routerProps:e})}}),i.a.createElement(V.a,{exact:!0,path:"/research/distopia",render:function(e){return i.a.createElement(q,{routerProps:e})}}),i.a.createElement(V.a,{exact:!0,path:"/research/communit",render:function(e){return i.a.createElement(P,{routerProps:e})}}),i.a.createElement(V.a,{exact:!0,path:"/research/cera",render:function(e){return i.a.createElement(B,{routerProps:e})}}),i.a.createElement(V.a,{exact:!0,path:"/designs/cuberpillar",render:function(e){return i.a.createElement(N,{routerProps:e})}}),i.a.createElement(V.a,{exact:!0,path:"/designs/ocularmd",render:function(e){return i.a.createElement(K,{routerProps:e})}}),i.a.createElement(V.a,{exact:!0,path:"/designs/ciac",render:function(e){return i.a.createElement(J,{routerProps:e})}}),i.a.createElement(V.a,{exact:!0,path:"/designs/lcl",render:function(e){return i.a.createElement(z,{routerProps:e})}}),i.a.createElement(V.a,{exact:!0,path:"/designs/cornellems",render:function(e){return i.a.createElement(H,{routerProps:e})}})))}}]),t}(a.Component);Boolean("localhost"===window.location.hostname||"[::1]"===window.location.hostname||window.location.hostname.match(/^127(?:\.(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)){3}$/));r.a.render(i.a.createElement(U.a,{basename:""},i.a.createElement(Y,null)),document.getElementById("root")),"serviceWorker"in navigator&&navigator.serviceWorker.ready.then(function(e){e.unregister()})}],[[20,2,1]]]);
//# sourceMappingURL=main.3a46fea7.chunk.js.map